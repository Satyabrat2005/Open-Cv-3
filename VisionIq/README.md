#  IQryx
### Ask Your Video Anything

> IQryx is a local-first video intelligence engine that converts raw video into searchable, explainable, evidence-grounded knowledge.

IQryx does not guess.  
IQryx does not hallucinate.  
IQryx **observes, remembers, and retrieves truth from video**.

This is not object detection.  
This is not captioning.  
This is **video intelligence infrastructure**.

---

##  What Is VisionIQ?

Video is everywhere â€” security cameras, meetings, factories, hospitals, research labs.  
Yet video remains the **least intelligent and least usable form of data**.

IQryx fixes that.

It transforms raw video into a **persistent semantic memory** that you can query using natural language.

Upload a video.  
IQryx watches it frame by frame.  
Ask a question.  
IQryx retrieves the exact visual evidence that answers it.

---

##  What Can You Ask?

- Where is the bottle in the video?
- When does the laptop first appear?
- What happens before the bottle becomes visible?
- Show scenes with both a backpack and a laptop.
- Which objects appear throughout the video?

IQryx answers using **what the video actually shows** â€” not assumptions, not guesses.

---

##  Why IQryx Exists

Most AI systems treat video as:
- static frames
- autogenerated captions
- black-box summaries

IQryx treats video as **experience over time**.

It combines:
- Vision
- Semantics
- Memory
- Retrieval

The result is **searchable, explainable, and auditable video understanding**.

---

## Core Capabilities (V1)

### Video Understanding
- Frame-by-frame video processing
- Temporal awareness (before / after / during)
- Object-level perception
- Optimized for DeepSeek-R1 integration

### Semantic Search
- Text-to-frame similarity search
- Robust to partial visibility
- Ranked, deterministic retrieval

### Intelligent Memory
- Vector-based storage using FAISS
- Persistent frame-level indexing
- Reusable intelligence (process once, query forever)

### Privacy First
- Fully local execution
- No cloud dependency
- Safe for sensitive and private videos

---

##  Advanced Capabilities (Planned)

- LLM-based reasoning over retrieved evidence
- Natural language answers with traceable explanations
- Multi-object logical queries (AND / OR)
- Cross-video semantic search
- Timeline-aware reasoning

---

## ðŸ—ï¸ System Architecture

Video
â†“
Frame Extraction (OpenCV)
â†“
Object Detection (YOLOv8)
â†“
Semantic Embeddings (CLIP)
â†“
Vector Memory (FAISS)
â†“
Query Engine
â†“
Ranked Visual Evidence
â†“
(LLM Reasoning â€“ Optional Layer)

The LLM never sees raw video.  
It reasons only over **filtered, retrieved evidence**.

---

##  Technology Stack

| Layer | Technology |
|-----|-----------|
| Video Processing | OpenCV |
| Object Detection | YOLOv8 |
| Embeddings | CLIP |
| Vector Store | FAISS |
| Query Engine | Python |
| Reasoning (Optional) | DeepSeek-R1 |
| Deployment | Local / On-Prem / SaaS-Ready |

---

##  Project Structure

IQryx/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ video_processor.py     # Frame extraction
â”‚   â”œâ”€â”€ object_detector.py     # YOLO detection
â”‚   â”œâ”€â”€ embedder.py            # Embedding generation
â”‚   â”œâ”€â”€ database.py            # FAISS vector memory
â”‚   â”œâ”€â”€ query_engine.py        # Retrieval logic
â”‚   â”œâ”€â”€ llm_engine.py          # (Optional) LLM reasoning
â”‚   â””â”€â”€ main.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ videos/
â”‚   â”œâ”€â”€ frames/
â”‚   â””â”€â”€ embeddings/
â”‚
â”œâ”€â”€ vision-iq-env/             # Virtual environment
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

---

##  Hardware Requirements

Recommended minimum:

- GPU: RTX 3060 / 4060 (8GB VRAM)
- RAM: 16 GB
- Storage: 20 GB+
- OS: Windows or Linux

Scales cleanly with better hardware.

---

##  Installation

Create virtual environment:

py -3.10 -m venv vision-iq-env

Activate environment (Windows):

.\IQryx-env\Scripts\Activate.ps1

Install dependencies:

pip install -r requirements.txt

---

##  Basic Query Engine (V1)

VisionIQ already supports **semantic video querying without any LLM**.

This baseline engine:
- embeds video frames
- stores them in vector memory
- retrieves relevant frames for text queries

Pure vision. Pure semantics. Zero hallucination.

---

##  Run the Query Engine

cd src
python test_query_engine.py

### Example Query

>> where is bottle

### Output (LLM-Free, Evidence-Only)

 VisionIQ Query (type 'exit' to quit)

ANSWER
--------------------------------------------------
I found 5 relevant scene(s) for your query:

1. Frame frame_00004.jpg (similarity 0.27)
2. Frame frame_00001.jpg (similarity 0.26)
3. Frame frame_00005.jpg (similarity 0.26)
4. Frame frame_00000.jpg (similarity 0.26)
5. Frame frame_00007.jpg (similarity 0.25)

ðŸ“· MATCHED FRAMES
--------------------------------------------------
Rank 1 | Score: 0.270 | Frame: frame_00004.jpg
Rank 2 | Score: 0.262 | Frame: frame_00001.jpg
Rank 3 | Score: 0.259 | Frame: frame_00005.jpg
Rank 4 | Score: 0.256 | Frame: frame_00000.jpg
Rank 5 | Score: 0.248 | Frame: frame_00007.jpg

---

##  VisionIQ Philosophy

AI should not just generate text.  
It should **understand reality**.

IQryx is built on the principle that:
- intelligence must be grounded
- memory must be persistent
- reasoning must be auditable

---

##  About NeuroTitan

IQryx is developed under **NeuroTitan AI Labs**, a research-driven initiative focused on:

- Applied AI systems
- Cognitive infrastructure
- Local-first intelligence
- AIâ€“semiconductor co-design

---

IQryx is not a demo.  
It is not a chatbot.  
It is not a toy.

It is **infrastructure for intelligent video systems**.

If you believe video should be **searchable, explainable, and trustworthy** â€”  
youâ€™re in the right place.
